{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to Generate dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: C:\\Users\\rushi\\Desktop\\Data set\\dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset path\n",
    "DATASET_PATH = r\"C:\\Users\\rushi\\Desktop\\Data set\"\n",
    "\n",
    "# Define categories (Deepfake folders = label 1, Original = label 0)\n",
    "categories = {\n",
    "    \"Deepfakes\": 1,\n",
    "    \"Face2Face\": 1,\n",
    "    \"FaceShifter\": 1,\n",
    "    \"FaceSwap\": 1,\n",
    "    \"NeuralTextures\": 1,\n",
    "    \"original\": 0\n",
    "}\n",
    "\n",
    "# Create a list to store file paths and labels\n",
    "data = []\n",
    "\n",
    "# Loop through each category folder\n",
    "for category, label in categories.items():\n",
    "    category_path = os.path.join(DATASET_PATH, category)\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"Warning: Folder not found -> {category_path}\")\n",
    "        continue\n",
    "\n",
    "    # Loop through video files in the folder\n",
    "    for video_name in os.listdir(category_path):\n",
    "        video_path = os.path.join(category_path, video_name)\n",
    "        \n",
    "        # Check if it's a valid file\n",
    "        if os.path.isfile(video_path):\n",
    "            data.append([video_path, label])\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"video_path\", \"label\"])\n",
    "\n",
    "# Save as CSV\n",
    "csv_path = os.path.join(DATASET_PATH, \"dataset.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved at: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\000_003.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\001_870.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\002_006.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\003_000.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\004_982.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\005_010.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\006_002.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\007_132.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\008_990.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\009_027.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\010_005.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\011_805.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\012_026.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\013_883.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\014_790.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\015_919.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\016_209.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\017_803.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\018_019.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\019_018.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\020_344.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\021_312.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\022_489.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\023_923.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\024_073.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\025_067.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\026_012.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\027_009.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\028_068.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\029_048.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\030_193.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\031_163.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\032_944.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\033_097.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\034_590.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\035_036.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\036_035.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\037_072.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\038_125.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\039_058.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\040_997.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\041_063.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\042_084.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\043_110.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\044_945.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\045_889.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\046_904.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\047_862.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\048_029.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\049_946.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\050_059.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\051_332.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\052_108.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\053_095.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\054_071.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\055_147.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\056_996.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\057_070.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\058_039.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\059_050.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\060_088.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\061_080.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\062_066.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\063_041.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\064_991.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\065_089.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\066_062.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\067_025.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\068_028.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\069_961.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\070_057.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\071_054.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\072_037.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\073_024.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\074_825.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\075_977.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\076_079.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\077_100.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\078_955.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\079_076.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\080_061.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\081_087.mp4\n",
      "Extracted 10 frames from C:\\Users\\rushi\\Desktop\\Data set\\Deepfakes\\082_103.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, total_frames \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m FRAMES_PER_VIDEO)  \u001b[38;5;66;03m# Pick frames evenly\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(FRAMES_PER_VIDEO):\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Jump to frame\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     success, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset CSV\n",
    "CSV_PATH = r\"C:\\Users\\rushi\\Desktop\\Data set\\dataset.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Folder to store extracted frames\n",
    "FRAME_SAVE_PATH = r\"C:\\Users\\rushi\\Desktop\\Data set\\frames\"\n",
    "os.makedirs(FRAME_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Number of frames to extract per video (adjust as needed)\n",
    "FRAMES_PER_VIDEO = 10\n",
    "\n",
    "# Process each video\n",
    "for index, row in df.iterrows():\n",
    "    video_path = row[\"video_path\"]\n",
    "    label = row[\"label\"]\n",
    "    \n",
    "    # Create label-specific folder\n",
    "    label_folder = os.path.join(FRAME_SAVE_PATH, str(label))\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    frame_count = 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(1, total_frames // FRAMES_PER_VIDEO)  # Pick frames evenly\n",
    "\n",
    "    for i in range(FRAMES_PER_VIDEO):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)  # Jump to frame\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        # Save frame as an image\n",
    "        frame_filename = f\"{os.path.basename(video_path).split('.')[0]}_frame{i}.jpg\"\n",
    "        frame_path = os.path.join(label_folder, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count} frames from {video_path}\")\n",
    "\n",
    "print(\"âœ… Frame extraction complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frames_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Frames dataset saved at: C:/Users/rushi/Desktop/Data set/frames_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "FRAMES_DIR = \"C:/Users/rushi/Desktop/Data set/frames\"\n",
    "DATASET_CSV = \"C:/Users/rushi/Desktop/Data set/dataset.csv\"\n",
    "OUTPUT_CSV = \"C:/Users/rushi/Desktop/Data set/frames_dataset.csv\"\n",
    "\n",
    "# Load existing dataset (to get video labels)\n",
    "df = pd.read_csv(DATASET_CSV)\n",
    "\n",
    "# Dictionary to store video-to-label mapping\n",
    "video_labels = dict(zip(df[\"video_path\"].apply(os.path.basename), df[\"label\"]))\n",
    "\n",
    "# Prepare new dataset\n",
    "frame_data = []\n",
    "\n",
    "# Traverse frames directory\n",
    "for root, _, files in os.walk(FRAMES_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith((\".jpg\", \".png\")):  # Only process image files\n",
    "            video_name = os.path.basename(root)  # Extract video name\n",
    "            frame_path = os.path.join(root, file)  # Full frame path\n",
    "            \n",
    "            # Assign label based on video name\n",
    "            label = video_labels.get(video_name, \"unknown\")  \n",
    "            \n",
    "            frame_data.append([frame_path, label])\n",
    "\n",
    "# Convert to DataFrame\n",
    "frame_df = pd.DataFrame(frame_data, columns=[\"frame_path\", \"label\"])\n",
    "\n",
    "# Save to CSV\n",
    "frame_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"âœ… Frames dataset saved at: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting frame into numpy array and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved batch 0 (1000 images)\n",
      "âœ… Saved batch 1 (1000 images)\n",
      "âœ… Saved batch 2 (1000 images)\n",
      "âœ… Saved batch 3 (1000 images)\n",
      "âœ… Saved batch 4 (1000 images)\n",
      "âœ… Saved batch 5 (1000 images)\n",
      "âœ… Saved batch 6 (1000 images)\n",
      "âœ… Saved batch 7 (1000 images)\n",
      "âœ… Saved batch 8 (1000 images)\n",
      "âœ… Saved batch 9 (1000 images)\n",
      "âœ… Saved batch 10 (1000 images)\n",
      "âœ… Saved batch 11 (1000 images)\n",
      "âœ… Saved batch 12 (1000 images)\n",
      "âœ… Saved batch 13 (1000 images)\n",
      "âœ… Saved batch 14 (1000 images)\n",
      "âœ… Saved batch 15 (1000 images)\n",
      "âœ… Saved batch 16 (1000 images)\n",
      "âœ… Saved batch 17 (1000 images)\n",
      "âœ… Saved batch 18 (1000 images)\n",
      "âœ… Saved batch 19 (1000 images)\n",
      "âœ… All images processed and saved as .npy files!\n",
      "âœ… Saved batch 0 (100 images)\n",
      "âœ… Saved batch 1 (100 images)\n",
      "âœ… Saved batch 2 (100 images)\n",
      "âœ… Saved batch 3 (100 images)\n",
      "âœ… Saved batch 4 (100 images)\n",
      "âœ… Saved batch 5 (100 images)\n",
      "âœ… Saved batch 6 (100 images)\n",
      "âœ… Saved batch 7 (100 images)\n",
      "âœ… Saved batch 8 (100 images)\n",
      "âœ… Saved batch 9 (100 images)\n",
      "âœ… Saved batch 10 (100 images)\n",
      "âœ… Saved batch 11 (100 images)\n",
      "âœ… Saved batch 12 (100 images)\n",
      "âœ… Saved batch 13 (100 images)\n",
      "âœ… Saved batch 14 (100 images)\n",
      "âœ… Saved batch 15 (100 images)\n",
      "âœ… Saved batch 16 (100 images)\n",
      "âœ… Saved batch 17 (100 images)\n",
      "âœ… Saved batch 18 (100 images)\n",
      "âœ… Saved batch 19 (100 images)\n",
      "âœ… Saved batch 20 (100 images)\n",
      "âœ… Saved batch 21 (100 images)\n",
      "âœ… Saved batch 22 (100 images)\n",
      "âœ… Saved batch 23 (100 images)\n",
      "âœ… Saved batch 24 (100 images)\n",
      "âœ… Saved batch 25 (100 images)\n",
      "âœ… Saved batch 26 (100 images)\n",
      "âœ… Saved batch 27 (100 images)\n",
      "âœ… Saved batch 28 (100 images)\n",
      "âœ… Saved batch 29 (100 images)\n",
      "âœ… Saved batch 30 (100 images)\n",
      "âœ… Saved batch 31 (100 images)\n",
      "âœ… Saved batch 32 (100 images)\n",
      "âœ… Saved batch 33 (100 images)\n",
      "âœ… Saved batch 34 (100 images)\n",
      "âœ… Saved batch 35 (100 images)\n",
      "âœ… Saved batch 36 (100 images)\n",
      "âœ… Saved batch 37 (100 images)\n",
      "âœ… Saved batch 38 (100 images)\n",
      "âœ… Saved batch 39 (100 images)\n",
      "âœ… Saved batch 40 (100 images)\n",
      "âœ… Saved batch 41 (100 images)\n",
      "âœ… Saved batch 42 (100 images)\n",
      "âœ… Saved batch 43 (100 images)\n",
      "âœ… Saved batch 44 (100 images)\n",
      "âœ… Saved batch 45 (100 images)\n",
      "âœ… Saved batch 46 (100 images)\n",
      "âœ… Saved batch 47 (100 images)\n",
      "âœ… Saved batch 48 (100 images)\n",
      "âœ… Saved batch 49 (100 images)\n",
      "âœ… Saved batch 50 (100 images)\n",
      "âœ… Saved batch 51 (100 images)\n",
      "âœ… Saved batch 52 (100 images)\n",
      "âœ… Saved batch 53 (100 images)\n",
      "âœ… Saved batch 54 (100 images)\n",
      "âœ… Saved batch 55 (100 images)\n",
      "âœ… Saved batch 56 (100 images)\n",
      "âœ… Saved batch 57 (100 images)\n",
      "âœ… Saved batch 58 (100 images)\n",
      "âœ… Saved batch 59 (100 images)\n",
      "âœ… Saved batch 60 (100 images)\n",
      "âœ… Saved batch 61 (100 images)\n",
      "âœ… Saved batch 62 (100 images)\n",
      "âœ… Saved batch 63 (100 images)\n",
      "âœ… Saved batch 64 (100 images)\n",
      "âœ… Saved batch 65 (100 images)\n",
      "âœ… Saved batch 66 (100 images)\n",
      "âœ… Saved batch 67 (100 images)\n",
      "âœ… Saved batch 68 (100 images)\n",
      "âœ… Saved batch 69 (100 images)\n",
      "âœ… Saved batch 70 (100 images)\n",
      "âœ… Saved batch 71 (100 images)\n",
      "âœ… Saved batch 72 (100 images)\n",
      "âœ… Saved batch 73 (100 images)\n",
      "âœ… Saved batch 74 (100 images)\n",
      "âœ… Saved batch 75 (100 images)\n",
      "âœ… Saved batch 76 (100 images)\n",
      "âœ… Saved batch 77 (100 images)\n",
      "âœ… Saved batch 78 (100 images)\n",
      "âœ… Saved batch 79 (100 images)\n",
      "âœ… Saved batch 80 (100 images)\n",
      "âœ… Saved batch 81 (100 images)\n",
      "âœ… Saved batch 82 (100 images)\n",
      "âœ… Saved batch 83 (100 images)\n",
      "âœ… Saved batch 84 (100 images)\n",
      "âœ… Saved batch 85 (100 images)\n",
      "âœ… Saved batch 86 (100 images)\n",
      "âœ… Saved batch 87 (100 images)\n",
      "âœ… Saved batch 88 (100 images)\n",
      "âœ… Saved batch 89 (100 images)\n",
      "âœ… Saved batch 90 (100 images)\n",
      "âœ… Saved batch 91 (100 images)\n",
      "âœ… Saved batch 92 (100 images)\n",
      "âœ… Saved batch 93 (100 images)\n",
      "âœ… Saved batch 94 (100 images)\n",
      "âœ… Saved batch 95 (100 images)\n",
      "âœ… Saved batch 96 (100 images)\n",
      "âœ… Saved batch 97 (100 images)\n",
      "âœ… Saved batch 98 (100 images)\n",
      "âœ… Saved batch 99 (100 images)\n",
      "âœ… Saved batch 100 (100 images)\n",
      "âœ… Saved batch 101 (100 images)\n",
      "âœ… Saved batch 102 (100 images)\n",
      "âœ… Saved batch 103 (100 images)\n",
      "âœ… Saved batch 104 (100 images)\n",
      "âœ… Saved batch 105 (100 images)\n",
      "âœ… Saved batch 106 (100 images)\n",
      "âœ… Saved batch 107 (100 images)\n",
      "âœ… Saved batch 108 (100 images)\n",
      "âœ… Saved batch 109 (100 images)\n",
      "âœ… Saved batch 110 (100 images)\n",
      "âœ… Saved batch 111 (100 images)\n",
      "âœ… Saved batch 112 (100 images)\n",
      "âœ… Saved batch 113 (100 images)\n",
      "âœ… Saved batch 114 (100 images)\n",
      "âœ… Saved batch 115 (100 images)\n",
      "âœ… Saved batch 116 (100 images)\n",
      "âœ… Saved batch 117 (100 images)\n",
      "âœ… Saved batch 118 (100 images)\n",
      "âœ… Saved batch 119 (100 images)\n",
      "âœ… Saved batch 120 (100 images)\n",
      "âœ… Saved batch 121 (100 images)\n",
      "âœ… Saved batch 122 (100 images)\n",
      "âœ… Saved batch 123 (100 images)\n",
      "âœ… Saved batch 124 (100 images)\n",
      "âœ… Saved batch 125 (100 images)\n",
      "âœ… Saved batch 126 (100 images)\n",
      "âœ… Saved batch 127 (100 images)\n",
      "âœ… Saved batch 128 (100 images)\n",
      "âœ… Saved batch 129 (100 images)\n",
      "âœ… Saved batch 130 (100 images)\n",
      "âœ… Saved batch 131 (100 images)\n",
      "âœ… Saved batch 132 (100 images)\n",
      "âœ… Saved batch 133 (100 images)\n",
      "âœ… Saved batch 134 (100 images)\n",
      "âœ… Saved batch 135 (100 images)\n",
      "âœ… Saved batch 136 (100 images)\n",
      "âœ… Saved batch 137 (100 images)\n",
      "âœ… Saved batch 138 (100 images)\n",
      "âœ… Saved batch 139 (100 images)\n",
      "âœ… Saved batch 140 (100 images)\n",
      "âœ… Saved batch 141 (100 images)\n",
      "âœ… Saved batch 142 (100 images)\n",
      "âœ… Saved batch 143 (100 images)\n",
      "âœ… Saved batch 144 (100 images)\n",
      "âœ… Saved batch 145 (100 images)\n",
      "âœ… Saved batch 146 (100 images)\n",
      "âœ… Saved batch 147 (100 images)\n",
      "âœ… Saved batch 148 (100 images)\n",
      "âœ… Saved batch 149 (100 images)\n",
      "âœ… Saved batch 150 (100 images)\n",
      "âœ… Saved batch 151 (100 images)\n",
      "âœ… Saved batch 152 (100 images)\n",
      "âœ… Saved batch 153 (100 images)\n",
      "âœ… Saved batch 154 (100 images)\n",
      "âœ… Saved batch 155 (100 images)\n",
      "âœ… Saved batch 156 (100 images)\n",
      "âœ… Saved batch 157 (100 images)\n",
      "âœ… Saved batch 158 (100 images)\n",
      "âœ… Saved batch 159 (100 images)\n",
      "âœ… Saved batch 160 (100 images)\n",
      "âœ… Saved batch 161 (100 images)\n",
      "âœ… Saved batch 162 (100 images)\n",
      "âœ… Saved batch 163 (100 images)\n",
      "âœ… Saved batch 164 (100 images)\n",
      "âœ… Saved batch 165 (100 images)\n",
      "âœ… Saved batch 166 (100 images)\n",
      "âœ… Saved batch 167 (100 images)\n",
      "âœ… Saved batch 168 (100 images)\n",
      "âœ… Saved batch 169 (100 images)\n",
      "âœ… Saved batch 170 (100 images)\n",
      "âœ… Saved batch 171 (100 images)\n",
      "âœ… Saved batch 172 (100 images)\n",
      "âœ… Saved batch 173 (100 images)\n",
      "âœ… Saved batch 174 (100 images)\n",
      "âœ… Saved batch 175 (100 images)\n",
      "âœ… Saved batch 176 (100 images)\n",
      "âœ… Saved batch 177 (100 images)\n",
      "âœ… Saved batch 178 (100 images)\n",
      "âœ… Saved batch 179 (100 images)\n",
      "âœ… Saved batch 180 (100 images)\n",
      "âœ… Saved batch 181 (100 images)\n",
      "âœ… Saved batch 182 (100 images)\n",
      "âœ… Saved batch 183 (100 images)\n",
      "âœ… Saved batch 184 (100 images)\n",
      "âœ… Saved batch 185 (100 images)\n",
      "âœ… Saved batch 186 (100 images)\n",
      "âœ… Saved batch 187 (100 images)\n",
      "âœ… Saved batch 188 (100 images)\n",
      "âœ… Saved batch 189 (100 images)\n",
      "âœ… Saved batch 190 (100 images)\n",
      "âœ… Saved batch 191 (100 images)\n",
      "âœ… Saved batch 192 (100 images)\n",
      "âœ… Saved batch 193 (100 images)\n",
      "âœ… Saved batch 194 (100 images)\n",
      "âœ… Saved batch 195 (100 images)\n",
      "âœ… Saved batch 196 (100 images)\n",
      "âœ… Saved batch 197 (100 images)\n",
      "âœ… Saved batch 198 (100 images)\n",
      "âœ… Saved batch 199 (100 images)\n",
      "ðŸŽ‰ All images saved as .npy files!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Set paths\n",
    "FRAMES_CSV = \"C:/Users/rushi/Desktop/Data set/frames_dataset.csv\"\n",
    "FRAMES_DIR = \"C:/Users/rushi/Desktop/Data set/frames\"\n",
    "IMG_SIZE = (64, 64)  # Resize images to reduce memory usage\n",
    "BATCH_SIZE = 1000  # Process images in batches\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(FRAMES_CSV)\n",
    "\n",
    "# Function to load images in batches\n",
    "def load_images(df, batch_size):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        frame_path = row['frame_path']\n",
    "        label = row['label']\n",
    "\n",
    "        # Load image\n",
    "        img = cv2.imread(frame_path)\n",
    "        \n",
    "        # Skip if image not found\n",
    "        if img is None:\n",
    "            continue  \n",
    "        \n",
    "        img = cv2.resize(img, IMG_SIZE)  # Resize to 64x64\n",
    "        img = img / 255.0  # Normalize (0-1)\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "\n",
    "        # Process in batches\n",
    "        if len(X) >= batch_size:\n",
    "            yield np.array(X), np.array(y)\n",
    "            X, y = [], []  # Reset batch\n",
    "\n",
    "    # Yield remaining data\n",
    "    if X:\n",
    "        yield np.array(X), np.array(y)\n",
    "\n",
    "# Save images to NumPy arrays efficiently\n",
    "output_dir = \"C:/Users/rushi/Desktop/Data set/numpy_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "for i, (X_batch, y_batch) in enumerate(load_images(df, BATCH_SIZE)):\n",
    "    np.save(os.path.join(output_dir, f\"X_batch_{i}.npy\"), X_batch)\n",
    "    np.save(os.path.join(output_dir, f\"y_batch_{i}.npy\"), y_batch)\n",
    "    print(f\"âœ… Saved batch {i} ({len(X_batch)} images)\")\n",
    "\n",
    "print(\"âœ… All images processed and saved as .npy files!\")\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Set paths\n",
    "FRAMES_CSV = \"C:/Users/rushi/Desktop/Data set/frames_dataset.csv\"\n",
    "FRAMES_DIR = \"C:/Users/rushi/Desktop/Data set/frames\"\n",
    "OUTPUT_DIR = \"C:/Users/rushi/Desktop/Data set/numpy_data\"\n",
    "\n",
    "IMG_SIZE = (64, 64)  # Resize images\n",
    "BATCH_SIZE = 100  # Reduce batch size for memory efficiency\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(FRAMES_CSV)\n",
    "\n",
    "# Function to load & save images in smaller batches\n",
    "def save_images(df, batch_size):\n",
    "    X, y = [], []\n",
    "    batch_index = 0  # Track batch number\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        frame_path = row['frame_path']\n",
    "        label = row['label']\n",
    "\n",
    "        # Read image\n",
    "        img = cv2.imread(frame_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"âŒ Skipping missing image: {frame_path}\")\n",
    "            continue  # Skip corrupt/missing images\n",
    "        \n",
    "        img = cv2.resize(img, IMG_SIZE)  # Resize\n",
    "        img = img / 255.0  # Normalize (0-1)\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "\n",
    "        # Save in batches\n",
    "        if len(X) >= batch_size:\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"X_batch_{batch_index}.npy\"), np.array(X))\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"y_batch_{batch_index}.npy\"), np.array(y))\n",
    "            print(f\"âœ… Saved batch {batch_index} ({len(X)} images)\")\n",
    "\n",
    "            # Clear memory\n",
    "            X, y = [], []\n",
    "            batch_index += 1  # Update batch number\n",
    "\n",
    "    # Save remaining images\n",
    "    if X:\n",
    "        np.save(os.path.join(OUTPUT_DIR, f\"X_batch_{batch_index}.npy\"), np.array(X))\n",
    "        np.save(os.path.join(OUTPUT_DIR, f\"y_batch_{batch_index}.npy\"), np.array(y))\n",
    "        print(f\"âœ… Saved last batch {batch_index} ({len(X)} images)\")\n",
    "\n",
    "# Run the function\n",
    "save_images(df, BATCH_SIZE)\n",
    "\n",
    "print(\"ðŸŽ‰ All images saved as .npy files!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load .npy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20000 images and 20000 labels.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set paths for the .npy files\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "# Load the batches of images and labels\n",
    "for i in range(200):  # Update this to the number of batches you have\n",
    "    X_batch = np.load(f\"C:/Users/rushi/Desktop/Data set/numpy_data/X_batch_{i}.npy\")\n",
    "    y_batch = np.load(f\"C:/Users/rushi/Desktop/Data set/numpy_data/y_batch_{i}.npy\")\n",
    "    \n",
    "    X_data.append(X_batch)\n",
    "    y_data.append(y_batch)\n",
    "\n",
    "# Concatenate all batches\n",
    "X_data = np.concatenate(X_data, axis=0)\n",
    "y_data = np.concatenate(y_data, axis=0)\n",
    "\n",
    "print(f\"Loaded {X_data.shape[0]} images and {y_data.shape[0]} labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (16000, 64, 64, 3), Testing data: (4000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {X_train.shape}, Testing data: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
